---
date_created: 2024-06-09
date_modified: 2024-06-09
---
TARGET DECK: Multimodal
START
Basic
Quali sono le 7 fasi dell'azione secondo Donald Norman?  (GPT)
Back:
Le 7 fasi dell'azione, conosciute anche come "Norman's Seven Stages of Action", sono un modello proposto da Donald Norman per comprendere il processo attraverso cui gli individui interagiscono con il mondo fisico e con sistemi tecnologici. Queste fasi sono:
- **Goal (Obiettivo)**: L'utente identifica un obiettivo che desidera raggiungere (definizione di goal).
- **Plan (Pianificazione)**: L'utente formula un piano per raggiungere l'obiettivo identificato (definizione intention)
- **Specify (Specificazione)**: L'utente traduce il piano in azioni specifiche.
- **Perform (Esecuzione)**: L'utente esegue le azioni specificate nel piano.
- **Perceive (Percezione)**: L'utente osserva gli effetti delle sue azioni.
- **Interpret (Interpretazione)**: L'utente interpreta gli effetti osservati in termini di successo o fallimento nel raggiungere l'obiettivo.
- **Compare (Confronto)**: L'utente confronta il risultato ottenuto con l'obiettivo desiderato e, se necessario, inizia nuovamente il ciclo di azione.

Questo modello aiuta progettisti e ricercatori a comprendere le interazioni umane con sistemi complessi, consentendo di identificare punti di forza e debolezza nell'interfaccia utente.
<!--ID: 1717958283431-->
END

---

START
Basic
Quali sono le 7 fasi dell'azione secondo Donald Norman? 
Back:
Norman Stages of action

Sono gli step da eseguire quando si compie un’azione multimodale.
1. Stabilire l'obiettivo: è, come al solito, la fase in cui l'utente determina ciò che deve essere fatto nel dominio.
2. Formare l'intenzione: in questa fase l'obiettivo è tradotto in una più precisa intenzione dell'utente, che lo aiuterà a determinare la giusta sequenza di azioni che deve essere eseguita per raggiungere l'obiettivo.
3. Specificare la sequenza d'azione multimodale: la sequenza di azioni eseguite per realizzare il compito richiesto deve essere precisamente indicato in questa fase.
4. Eseguire l'azione multimodale: in questa fase, ogni movimento umano utilizzato per specificare l'azione viene interpretato. Testo, parlato, Braille, imitazione, cattura dell'occhio/movimento, aptica, sensoristica bioelettrica sono esempi di modalità utilizzate per tradurre le modalità di output umano nel linguaggio di input del sistema. Ogni azione è eseguita attraverso modes complementari o modes alternativi
5. Percepire lo stato del sistema: a questo punto ha inizio la fase di valutazione del ciclo. A seconda dell’azione compiuta dall’utente e a seconda di come il sistema risponde, l'utente può percepire il nuovo stato attraverso più modalità sensoriali, come quelle visivi, uditivi, tattili, e (in alcune interfacce rivoluzionarie) anche odore e degustazione.
6. Interpretazione lo stato del sistema: Qui l'utente dovrebbe interpretare l’output ricevuto scaturito dal suo / sua sequenza di azioni per valutare quanto è accaduto.
7. Valutare lo stato del sistema per quanto riguarda gli obiettivi e le intenzioni: nella fase finale, l'utente confronta il nuovo stato del sistema con le sue aspettative, per valutare se l'obiettivo iniziale è stato effettivamente raggiunto.
<!--ID: 1717958283433-->
END

---

START
Basic
Definizione Formale di modalità 
Back:
Una modalità in un sistema multimodale è un processo che riceve e produce blocchi di informazioni. Formalmente, una modalità M è definita da:
- E(M): L'insieme di blocchi di informazioni ricevute da M.
- S(M): L'insieme di blocchi di informazioni prodotte da M.

Le modalità possono cooperare in diversi modi:
1. **Equivalenza:** Diverse modalità cooperano per equivalenza se le stesse informazioni possono essere trattate in alternativa da una di esse.
2. **Specializzazione:** Le modalità cooperano per specializzazione se una determinata tipologia di informazione è sempre trattata dalla stessa modalità.
3. **Ridondanza:** Le modalità cooperano in ridondanza se le stesse informazioni sono trattate con queste modalità.
4. **Complementarità:** Diverse modalità cooperano per complementarietà se informazioni diverse vengono elaborate da ciascuna modalità ma devono essere unite.
5. **Trasferimento:** Le modalità cooperano tramite trasferimento se le informazioni prodotte da una modalità sono utilizzate da un'altra modalità.
6. **Concorrenza:** Più modalità cooperano in modo simultaneo se informazioni diverse vengono elaborate da più modalità contemporaneamente ma non devono essere unite.
<!--ID: 1717958283435-->
END

---
START
Basic
Definizioni varie
Back:
- **Multimedia:** Ha a che fare con la struttura dei dati.
- **Multimodal:** Ha a che fare con il canale di comunicazione.
- **Multimodal Interfaces:** Caratterizzate dall'uso possibilmente simultaneo di più modalità sensoriali umane e possono supportare modalità di input/output combinate.
- **Mode vs Modalità:** Un modo possibile, consueto o preferito di fare qualcosa. Nelle interfacce multimodali, influenza il modo in cui le informazioni vengono veicolate. La modalità può essere definita come una delle vie della sensazione (es. la visione), dove tutte le modalità sfruttano il canale visivo.
- **Media:** Hardware/software che permette l'interazione tra un utente e un sistema secondo un dato insieme di modi (modalità). Ad esempio, per le modalità uditive abbiamo molti possibili media come voce, suono, rumore.
- **Sensi:** I classici 5 sensi (gusto, olfatto, vista, udito e tatto) che permettono di catturare le informazioni.
<!--ID: 1717958283437-->
END

---



START
Basic
Cosa significa l'acronimo GOMS?  (ok)
Back:
GOMS è un acronimo che sta per "**Goals, Operators, Methods, and Selection rules**". È un modello di analisi cognitiva utilizzato per valutare l'efficienza e la complessità dei sistemi interattivi. Ogni componente dell'acronimo GOMS rappresenta un aspetto specifico dell'analisi:

- **Goals (Obiettivi)**: Rappresentano gli obiettivi che l'utente deve raggiungere utilizzando il sistema.
- **Operators (Operatori)**: Sono le azioni elementari che l'utente può compiere per raggiungere gli obiettivi.
- **Methods (Metodi)**: Indicano le sequenze di operatori utilizzate per raggiungere gli obiettivi.
- **Selection rules (Regole di selezione)**: Definiscono le condizioni che determinano quale metodo viene utilizzato in una data situazione.

GOMS è utile per identificare potenziali problemi di progettazione e per ottimizzare le interfacce utente al fine di massimizzare l'efficienza e la facilità d'uso.
<!--ID: 1717958283438-->
END

---

START
Basic
Che cos'è l'HTA (Hierarchical Task Analysis)?  
Back:
L'HTA (**Hierarchical Task Analysis**) è un metodo di analisi che scompone le attività complesse in compiti più piccoli e gestibili, organizzati in una struttura gerarchica. Questo metodo consente di comprendere le azioni che gli utenti eseguono per raggiungere determinati obiettivi e di identificare i requisiti dell'utente per un sistema o un'interfaccia. L'HTA aiuta i progettisti a identificare le sequenze di azioni più comuni e importanti per gli utenti, nonché le potenziali aree di difficoltà o inefficienza. Questo approccio dettagliato alla progettazione dell'interfaccia utente aiuta a garantire che i sistemi siano intuitivi e facili da usare per gli utenti finali.
ESTENSIONE 
Nella sua forma più elementare, un'analisi gerarchica delle attività fornisce una comprensione
delle attività che gli utenti devono eseguire per raggiungere determinati obiettivi.
Nell'esperienza utente, puoi utilizzare l'analisi delle attività gerarchiche per descrivere le
interazioni tra un utente e un sistema software. Quando si progetta un nuovo sistema, l'analisi
gerarchica delle attività consente di esplorare vari possibili approcci per completare la stessa
attività.
Esempio, sempre relativo alla pulizia della casa:
Descrizione della gerarchia:
Main task
0. Pulire la casa
Sub task
1) Prendere l’aspirapolvere
2) Prendere i corretti accessori
3) Pulire le stanze
i. Pulire la sala
ii. Pulire la cucina
iii. Pulire il bagno
iv. Pulire le camere
4) Svuotare il cesto dei panni sporchi
5) Rimettere a posto l’aspirapolvere e gli accessori

Descrizione del piano: I viene definito a partire dal padre (dal primo punto prima dei figli) e può
essere fatto per ogni livello purché ci siano figli al di sotto.
- Piano 0: eseguire punti 1-2-3-5 in ordine, quando il cesto dei panni sporchi è pieno esegui il
punto 4
- Piano 3: esegui i punti i, ii, iii o iv in qualsiasi ordine, sempre in accordo con le stanze da
pulire.
N.B. SOLO IL PIANO DENOTA L’ORDINE!
Come posso generare la gerarchia?
- Prendi la lista dei task;
- Raggruppare le attività in attività di livello superiore;
- Scomponi ulteriormente le attività di livello inferiore;
In questa analisi gerarchica dell'attività, vengono suddivise le attività in sotto-attività, esprimendo
le relazioni tra l'attività principale e le sue attività secondarie attraverso uno schema di numerazione. Questa analisi gerarchica delle attività è molto grossolana dal punto di vista dell'esperienza dell'utente. Non comunica nulla su ciò che sta accadendo a livello di interazione
dell'utente con il sistema. Tuttavia, fornisce una chiara comprensione dei passaggi di alto livello dell'attività.
<!--ID: 1717958283440-->
END

---

START
Basic
Timed automata  
Back:
Timed automata sono un tipo di automi utilizzati per descrivere sistemiche evolvono nel tempo. Ogni stato di un timed automaton è associato a un orologio che tiene traccia del tempo trascorso dall'ingresso nello stato. Le transizioni tra gli stati possono essere condizionate dall'attivazione di un orologio, consentendo di modellare comportamenti temporizzati nei sistemi.
ESTESA
Più in dettaglio, un automa temporizzato è un automa standard a stati finiti esteso con una raccolta finita di orologi a valori reali.
Le transizioni di un automa temporizzato sono etichettate con una guardia (una condizione sugli orologi), un'azione e un ripristino dell'orologio (un sottoinsieme di orologi da ripristinare).

L’automa temporizzato composto da:
- Uno stato di un automa è una coppia composta da un nodo di controllo e un'assegnazione di clock, ovvero l'impostazione corrente degli orologi.
- Le transizioni sono etichettate con un'azione (se si tratta di un passaggio istantaneo dal nodo corrente a un altro) o un numero reale positivo, cioè un ritardo (se l'automa rimane all'interno di un nodo lasciando passare il tempo).
- Il tempo di incorporamento consente di modificare lo stato delle entità coinvolte in base aeventi basati sul tempo.
<!--ID: 1717958283441-->
END

---

START
Basic
Error Handling/Error detection
Back:
1. input mancante,
2. rifiuto di riconoscimento,
3. il riconoscitore restituisce qualcosa che non può essere interpretato (non ha alcun senso),
4. il riconoscitore restituisce qualcosa che non è semanticamente coerente,
5. il riconoscitore restituisce frasi semanticamente ben formate, ma impossibili da soddisfare,
6. come il punto 5, con l'eccezione che l'impossibilità è dovuta al contesto del dialogo,
7. il sistema backend non riesce a soddisfare il comando (ad esempio, connessione al database persa),
8. correzione degli errori iniziata dall'utente: l'utente può rilevare molti tipi di errori,
errori di riconoscimento vocale che non risultano in nessuno dei tipi di errore sopra menzionati e che non possono essere identificati dai punteggi di riconoscimento e dallo stato del dialogo, possono essere rilevati solo dall'utente,

Il progettista del sistema deve assicurarsi che l'utente possa individuare e correggere ogni possibile errore che può verificarsi, e anche che l'utente sappia come correggerli.
<!--ID: 1717958283443-->
END

---
START
Basic
Error Handling/Repair
Back:
La progettazione della riparazione degli errori avviene dopo che la causa dell'errore è stata dedotta, il sistema decide come gestire l'errore, cioè seleziona una strategia di correzione dell'errore adeguata.

Nel caso ideale, sia i costi dell'errore che i costi della correzione dell'errore vengono calcolati e confrontati,

Si devono considerare il tipo di errore, lo stato del dialogo e le informazioni sugli errori e le riparazioni passate,

Ipotesi possibile: se i costi della correzione dell'errore sono inferiori ai costi causati dall'errore, la correzione dell'errore è giustificata,
altrimenti, la correzione dell'errore dovrebbe essere omessa.
<!--ID: 1717958283444-->
END

---

START
Basic
Error Handling/Error correction
Back:
Il sistema avvia un dialogo di correzione dell'errore, come una conferma, una domanda sì/no, una riformulazione, una ripetizione, uno spelling o una selezione da un elenco, per correggere l'errore.

È importante rendersi conto che la correzione dell'errore è un dialogo in sé, e viene eseguita come qualsiasi altro dialogo, e possono verificarsi ulteriori errori durante il dialogo di correzione.

Le conferme sono utilizzate nella maggior parte delle applicazioni vocali per correggere gli errori:

Possono essere viste come parte della gestione degli errori,

Possono anche essere viste come elementi dell'interfaccia del dialogo normale per garantire che i partecipanti abbiano una comprensione comune delle informazioni (grounding).
<!--ID: 1717958283445-->
END

---

START
Basic
Grounding
Back:
Il grounding è il processo mediante il quale i partecipanti a una conversazione assicurano di avere una comprensione comune delle informazioni scambiate. In altre parole, è il meccanismo attraverso il quale i parlanti confermano di aver compreso e accettato ciò che è stato detto, garantendo che non ci siano malintesi. Questo può avvenire tramite conferme, riformulazioni, ripetizioni o altre forme di feedback durante il dialogo.
<!--ID: 1717958283447-->
END

---


START
Basic
Error handling/grounding 
Back:
Error handling/grounding si riferisce ai metodi utilizzati nei sistemi interattivi per gestire gli errori dell'utente e stabilire una base comune di comprensione tra l'utente e il sistema. L'**error handling** riguarda la gestione degli errori di input dell'utente, mentre il **grounding** si concentra sulla creazione di un terreno comune di comprensione tra utente e sistema, riducendo l'ambiguità nella comunicazione e garantendo che l'interazione sia efficace.
<!--ID: 1717958283448-->
END

---

START
Basic
Multimodal coordination types  
Back:
I tipi di coordinamento multimodale si riferiscono ai modelli utilizzati per integrare e coordinare più modalità di input e output in un sistema interattivo. Questi possono includere coordinazione **sequenziale**, **parallela** o **sincronizzata** delle modalità sensoriali come la visione, l'udito e il tatto. Il coordinamento multimodale è importante per migliorare l'esperienza utente e consentire interazioni più fluide e naturali con i sistemi tecnologici.
<!--ID: 1717958283449-->
END

---

START
Basic
Input fusion levels  
Back:
I livelli di fusione dell'input si riferiscono ai diversi modi in cui le informazioni provenienti da modalità sensoriali multiple vengono integrate e processate all'interno di un sistema interattivo. Questi livelli possono includere la fusione **basso**, **medio** e **alto** livello, a seconda del grado di integrazione delle informazioni sensoriali e della complessità del processo decisionale.
<!--ID: 1717958283451-->
END

---

START
Basic
Context of fission  
Back:
Il contesto della **fission** si riferisce al processo di suddivisione di un'interazione complessa in componenti più piccoli e gestibili, al fine di semplificare la progettazione e migliorare l'usabilità. Questo approccio consente di concentrarsi su singoli aspetti dell'interazione e di ottimizzare l'esperienza utente in modo più efficace.
<!--ID: 1717958283453-->
END

---

START
Basic
Context of fission  (non gpt)
Back:
Una questione importante per i processi di comunicazione, e per l'interazione multimodale, è la
disposizione e l'organizzazione dell'output dell'informazione ovvero la fissione multimodale.
Per fissione quindi si intende il modo in cui si presenta l’output all’utente.
Alcuni aspetti da considerare nella progettazione e nella configurazione della fissione sono:
- Per l’output vocale: la struttura dell’informazione, l'intonazione e l'enfasi.
- Per l’output visivo: coordinamento spazio-temporale delle parti di informazione(video,
grafica, immagini e testi).
Bisogna progettare un output appropriato per ogni tipo di modalità e bisogna sincronizzare le
uscite se si usano diverse modalità.
Il processo di fissione deve considerare quali informazioni devono essere presentate in base al
contesto di interazione e come queste informazioni possono essere presentate in termini di
struttura dell'informazione, le modalità scelte per l'output e il loro
coordinamento/sincronizzazione.
Per ciascun canale di comunicazione ci sono degli elementi che ci indicano la struttura delle
informazioni da mostrare. Ad esempio:
- Per l’outupt Vocale: strutture sintattiche, l'ordine delle parole, l'intonazione e la prosodia
- Per l’output Visivo: la presentazione della disposizione degli oggetti.
Per quanto riguarda il focus sul contesto, la letteratura propone molte definizioni di contesto e in
particolare di contesto di interazione.
Schilit ed altri hanno affermato che gli aspetti importanti del contesto sono: dove si trova l'utente,
con chi è l'utente e quali risorse si trovano nelle vicinanze.
Definiscono il contesto come ambiente di esecuzione in continua evoluzione. L'ambiente è triplice:
1. Ambiente informatico: processori disponibili, dispositivi accessibili per l'input e la
visualizzazione dell'utente, capacità di rete, connettività e costi di elaborazione.
2. Ambiente dell'utente: posizione, raccolta di persone vicine e situazione sociale.
3. Ambiente fisico: illuminazione e livello di rumore.
<!--ID: 1717958283455-->
END

---


START
Basic
Advanced haptic  
Back:
Nel contesto dell'haptics nella realtà aumentata/virtuale, è possibile aggiungere **ulteriori feedback** sulle altre qualità di un materiale/oggetto che si sta simulando. Ad esempio, se si sta simulando il **peso di un oggetto**, è possibile utilizzare un dispositivo che esercita una **forza contraria** per simulare la sensazione di peso.
<!--ID: 1717958283456-->
END

---

START
Basic
Fission  
Back:
La **fission** è il processo di suddivisione di un'interazione complessa in componenti più piccoli e gestibili al fine di semplificarne la progettazione e migliorare l'usabilità. Questo approccio consente di concentrarsi su singoli aspetti dell'interazione e di ottimizzare l'esperienza utente in modo più efficace.
<!--ID: 1717958283457-->
END

---

START
Basic
Fission  (NON GPT)
Back:
La fissione significa come deve essere presentato l’output.

Una questione importante per l'interazione multimodale è come generare e organizzare l‘output delle informazioni = fissione multimodale.

Alcuni aspetti da considerare nella progettazione e nella configurazione della fissione ad esempio:
- Per l’output vocale: la struttura dell’informazione, l'intonazione, e l'enfasi.
- Per l’output visivo: coordinamento spazio-temporale delle parti di informazione(video, grafica, immagini e testi).

Bisogna progettare un output appropriato per ogni tipo di modalità

Bisogna sincronizzare le uscite se si usano diverse modalità Il processo di fissione deve considerare quali informazioni devono essere presentata in base all’input e di come queste informazioni possono essere presentate in termini di struttura, di modalità e di scelte per l'uscita. 

Per ciascun canale di comunicazione ci sono degli elementi che ci indicano la struttura delle informazioni da mostrare. Ad esempio:
- Per l’outupt Vocale: strutture sintattiche, l'ordine delle parole, l'intonazione e la prosodia
- Per l’output visivo: la presentazione della disposizione degli oggetti.

Il primo modello concettuale per la presentazione multimodale di informazioni e per la progettazione di sistemi di output multimodale è WWHT (What-Which- How-Then) :
- What: Quali sono le informazioni da presentare?
- Which: Quali modalità dovremmo utilizzare per presentare queste informazioni?
- How: Come presentare le informazioni utilizzando le modalità scelte?
- Then: Quindi, come gestire l'evoluzione della presentazione? 
<!--ID: 1717958283459-->
END

---

START
Basic
Acoustic and Language model for SR (Speech Recognition)  
Back:
I modelli acustici e linguistici per il riconoscimento vocale (SR) sono componenti fondamentali dei sistemi di riconoscimento vocale. Il **modello acustico** si occupa di convertire il segnale audio in una sequenza di simboli fonetici, mentre il **modello linguistico** si occupa di determinare la sequenza più probabile di parole o frasi basandosi sul contesto linguistico. Questi modelli sono essenziali per garantire un'accurata trascrizione del parlato in testo.
<!--ID: 1717958283460-->
END

---

START
Basic
Speaker dependent/Independent  
Back:
Speaker dependent e speaker independent si riferiscono alle caratteristiche dei sistemi di riconoscimento vocale. Un sistema **speaker dependent** richiede un adattamento specifico per ciascun utente, mentre un sistema **speaker independent** è progettato per riconoscere la voce di qualsiasi utente senza richiedere un adattamento individuale. I sistemi speaker independent sono più flessibili e possono essere utilizzati da più utenti senza la necessità di una fase di adattamento.
<!--ID: 1717958283462-->
END

---

START
Basic
Iniziative di dialogo 
Back:
Domanda:
I tre tipi di strategie di dialogo in un sistema multimodale sono:
1. System initiative dialogue strategy: Il computer pone domande all'utente e, una volta ricevute le informazioni necessarie, viene calcolata una soluzione e viene prodotta una risposta.
2. User initiative dialogue strategy: Il sistema attende gli input dell'utente e reagisce eseguendo le operazioni corrispondenti, presupponendo che l'utente sappia come interagire con il sistema.
3. Mixed initiative dialogue strategy: L'iniziativa può essere presa sia dall'utente che dal sistema, consentendo una combinazione di interazioni guidate dall'utente e dal sistema.
<!--ID: 1717958283463-->
END

---

START
Basic
Eyetracking, cos’è tecniche
Back:
Eye tracking misura o dove stiamo guardando o il movimento di un occhio relativo alla testa.

**Tipo di tecniche per il tracciamento oculare:**
- **Telecamera:**
  - **Bright Pupil:** L'occhio è illuminato direttamente dalla luce, facendo sì che la pupilla appaia luminosa.
  - **Dark Pupil:** La luce è spostata rispetto all'occhio, rendendo la pupilla scura.

- **Altre tecniche:**
  - **Elettroculografia:** Utilizzo di elettrodi sotto gli occhi per rilevare movimenti oculari attraverso la variazione di tensione elettrica.
  - **Oculografia infrarossi:** Rilevamento della posizione dell'occhio tramite variazione della luce riflessa verso un rilevatore fisso.

**Fase di calibrazione:**
- Regola le differenze individuali nei movimenti oculari per migliorare l'accuratezza del sistema di tracciamento.

**Utilità dell'eye tracking:**
- **Heat Map:** Indica le aree più osservate nel video con codifiche colore.
- **Gaze Paths:** Traccia il percorso degli occhi quando si muovono sullo schermo.
- **Areas of Interest:** Identifica le parti dell'interfaccia che catturano maggiormente l'attenzione.

**Pattern di lettura:**
- **F-shaped pattern:** Gli utenti tendono a seguire uno schema di lettura a forma di F, con movimenti orizzontali seguiti da uno verticale sul lato sinistro del contenuto.

**Consigli per catturare l'attenzione:**
- I primi due paragrafi devono contenere le informazioni più importanti.
- Gli utenti tendono a leggere più del primo paragrafo rispetto al secondo.
<!--ID: 1717958283469-->
END

---

START
Basic
Cooperation policies  
Back:
Un sistema multimodale ha diverse modalità di input (visivo, uditivo, ecc.). Ogni modalità ha caratteristiche che devono essere programmate dallo sviluppatore. Per la cooperazione delle diverse modalità sono necessari tre componenti:
1. **Riconoscitore di modalità:** Capisce da quale modalità di input arriva il segnale dell'utente.
2. **Modulo per la fusione dell'input multimodale:** Riceve l'input dal riconoscitore e fonde i risultati in un unico blocco completo per l'applicazione.
3. **Modulo di feedback:** Accetta un blocco completo dall'applicazione e fornisce feedback agli utenti tramite l’uscita multimodale.

**Definizione formale di modalità:**
- **E(M):** Insieme di blocchi di informazioni ricevute da M.
- **S(M):** Insieme di blocchi di informazioni prodotte da M.

**Modalità di cooperazione:**
1. **Equivalenza:** Un pezzo di informazione può essere elaborato da una delle diverse modalità indistintamente. Aumenta la personalizzazione e l'equivalenza = alternativa.
2. **Ridondanza:** Le stesse informazioni possono essere processate da entrambe le modalità. Esempio: digitare e pronunciare "uscire" evita il dialogo di conferma.
3. **Complementarietà:** I diversi blocchi di informazioni sono trattati singolarmente da singole modalità, poi fusi insieme. Permette interazione più veloce e migliore riconoscimento di messaggi brevi.
4. **Concorrenza:** I diversi pezzi di informazione vengono elaborati da diverse modalità contemporaneamente, ma non devono essere uniti. Permette interazione veloce utilizzando modalità in parallelo. La complementarietà può migliorare l'interpretazione.
<!--ID: 1717958283471-->
END

---

START
Basic
Perché è importante modellare il software 
Back:
**Importanza del modellare il software nei sistemi normali:**
- Identificazione delle componenti del progetto.
- Valutazione delle complicazioni derivanti dai requisiti.
- Mantenimento a lungo termine del software.

**Importanza del modellare il software nelle interfacce multimodali:**
- Necessità di componenti separate per ogni canale, ma anche di supporto alla comunicazione e sincronizzazione tra diverse modalità di input.
- Maggiore difficoltà nella stabilizzazione e verifica dei requisiti.
- Possibile necessità di una separazione netta per sfruttare progressi tecnologici a ritmi diversi.

**Importanza del modellare i software interattivi nei sistemi normali:**
- Mantenimento di coerenza tra diversi sistemi di definizione.
- Identificazione e valutazione della corrispondenza tra il linguaggio degli utenti e quello di interazione.
- Valutazione della corrispondenza tra gli strumenti di interazione e l'applicazione logica.

**Importanza del modellare i software interattivi nelle interfacce multimodali:**
- Necessità di affrontare la consistenza nell'uso di canali diversi.
- Espansione delle modalità di linguaggio degli utenti che devono essere coordinate.
- Sfruttamento dei vantaggi della multi-modalità nella logica dell'applicazione.
<!--ID: 1717958283472-->
END

---


START
Basic
When the fusion is needed? (When we are in the case of redundancy and complementarity)  
Back:
La **fusione** è necessaria quando ci troviamo di fronte a situazioni di **ridondanza** e **complementarietà** tra le informazioni provenienti da diverse modalità sensoriali. In questi casi, la fusione delle informazioni può migliorare la robustezza e l'affidabilità del sistema, consentendo una migliore comprensione dell'ambiente circostante e delle intenzioni dell'utente.
<!--ID: 1717958283474-->
END

---

START
Basic
Perceptual (non vi è interazione con controller, quindi visivo, audio, gesture) / Non Perceptual (tramite mouse, penne, ed altri controller)  
Back:
- **Non-Perceptual input**: prevedono l'utilizzo di dispositivi o oggetti che vengono utilizzati per inserire il gesto, quindi richiede il contatto fisico per trasmettere posizione, informazioni spaziale o temporale al processore del computer. Uno dei primi esempi di sistemi di input non-perceptual era lo SketchPad di Sutherland (1963) che utilizzava una penna ottica, un predecessore al mouse, per indicare la posizione di un oggetto in una pagina. I gesti che usano il mouse permettono la manipolazione diretta o la “punta e clicca” per interagire con un computer. Altri esempi sono i touch-screen, i guanti elettronici, laser infrarossi per tracciare i movimenti
- **Perceptual input**: consente di riconoscere i gesti senza alcun contatto fisico con un dispositivo di ingresso o con qualsiasi oggetto fisico. L'utente può comunicare con i gesti senza dover indossare, tenere o essere a contatto fisico con un dispositivo intermedio quale un guanto o un mouse. Hanno bisogno di una tecnologia di input percettivo che comprende sensori visivi, audio o sensori come, ad esempio, quello di movimento che sono in grado di ricevere dati di input da parte dell'utente.
<!--ID: 1717958283475-->
END

---

START
Basic
What is Fission (come deve essere presentato l’output)  
Back:
La **fission** è un concetto che si riferisce alla suddivisione di un'interazione complessa in componenti più gestibili per semplificarne la progettazione e migliorare l'usabilità complessiva. Quando si presenta l'output della fission, è importante considerare la **chiarezza** e la **coerenza**. L'output dovrebbe essere presentato in modo **logico** e **organizzato**, facilitando la comprensione e l'utilizzo da parte dell'utente. È essenziale che l'output sia **accurato** e **rilevante** per le esigenze dell'utente, fornendo le informazioni necessarie in modo **chiaro** e **conciso**. Inoltre, è utile includere elementi visivi come **grafici**, **tabelle** o **diagrammi** per migliorare la comprensione dell'output da parte dell'utente.
<!--ID: 1717958283476-->
END
---

Basic
CCT
Back:
CCT (Cognitive Complexity Theory) 

Le caratteristiche principali di CTT sono:
- Consente ai progettisti di concentrarsi sulle attività che gli utenti intendono svolgere, che sono gli aspetti più rilevanti nella progettazione di applicazioni interattive che comprendano sia gli aspetti relativi all'utente che quelli relativi al sistema, evitando dettagli di implementazione di basso livello che in fase di progettazione sarebbero solo oscurare le decisioni da prendere.
- Ha una struttura gerarchica, qualcosa di molto intuitivo, infatti spesso quando le persone devono risolvere un problema tendono a scomporlo in problemi più piccoli mantenendo comunque le relazioni tra le varie parti della soluzione.
- Utilizza una sintassi grafica, spesso (anche se non sempre) è più facile da interpretare. In questo caso riflette la struttura logica quindi ha una forma ad albero.

Una volta che le attività sono state identificate è possibile indicare gli oggetti che devono essere manipolati per supportarne le prestazioni. Si possono considerare due tipi generali di oggetti: o gli oggetti dell'interfaccia utente o gli oggetti del dominio dell'applicazione.
END
---

START
Basic
UIMS(User Interface Management Systems)
Back:
Un **UIMS (User Interface Management System)** è un meccanismo che **controlla la relazione tra la presentazione e le funzionalità**, in altre parole controlla la relazione tra l’interfaccia e le operazioni che si svolgono attraverso vari canali (voce, gesti, ecc.). Un UIMS è uno strumento o un insieme di strumenti che aiuta a specificare, implementare, testare e mantenere un'interfaccia utente. Esso migliora:
- **Portabilità:** abilità di usare il sistema su dispositivi differenti, molto complesso nel caso di interfacce multimodali.
- **Ri-usabilità:** riusare le componenti per ridurre le spese.
- **Interfacce multiple:** per accedere alle stesse funzionalità. In interfacce multimodali, le interfacce multiple implicano multipli canali.
- **Personalizzazione:** per il designer e l’utente, a seconda delle necessità.
<!--ID: 1717958283478-->
END
---

START
Basic
Descrivi il modello Seehein evidenziandone le sue difficoltà (UIMS)
Back:
Nel modello Seehein, sviluppato negli anni '80 durante un workshop UIMS a Seehein in Germania, il software è separato in tre parti:
1. **Presentation component:** definisce il comportamento del sistema percepito e manipolato dall'utente.
2. **Application interfaces component:** fornisce l'interfaccia con una vista dell'applicazione e gestisce la comunicazione con l'applicazione.
3. **Dialogue component:** un mediatore tra l’application interfaces component e la presentation component.

Dalle tre componenti otteniamo tre tipi di feedback:
1. **Lexical:** rappresenta il codice per esprimere che il sistema ha capito l'intento dell'utente di spostare il focus dell'azione su un'altra cosa (ad esempio, il movimento del mouse).
2. **Syntactic:** regole sintattiche che devono essere rispettate, come una voce di menu selezionata deve essere evidenziata, o un determinato tasto premuto esegue una determinata azione.
3. **Semantic:** il risultato dell'azione compiuta, come il numero sulla calcolatrice che cambia a seguito di una somma. Il feedback semantico è il più lento, ma in molti casi è necessaria una valutazione semantica più veloce (ad esempio, evidenziare il cestino dei rifiuti sul desktop quando un documento viene spostato nelle vicinanze).

Due difficoltà principali nel modello Seehein sono:
1. Quando si cambia un componente di presentazione, il dialogue control deve essere riscritto per adattarsi alle nuove caratteristiche.
2. Il dialogue control tende a basarsi sulla presentazione, e la presentazione deve essere cambiata ogni volta che il dialogue cambia.

Gestendo ogni blocco in maniera indipendente, possiamo fornire gli stessi strati esterni per diverse applicazioni. Ad esempio, cambiando solo il dialogue possiamo applicare lo stesso aspetto grafico a un editor di testo come Word e a un foglio di calcolo come Excel. In questo modo, l'utente non deve imparare diverse lingue di dialogo per diverse applicazioni, come avviene nei prodotti Microsoft.
<!--ID: 1717958283479-->
END

---



START
Basic
Gestalt Laws (Proximity, Similarity, Closure, Good Continuation, Common Fate, Good Form, Experience), leggi di Gestalt  
Back:
Cosa vedi in questa immagine?

Se sei come la maggior parte delle persone, probabilmente vedrai un triangolo. Ma in realtà, tutto quello che c'è sono tre "pac man" bianchi. Vediamo il triangolo perché il nostro cervello prende le informazioni visive ambigue e le organizza in qualcosa che ha senso per noi, qualcosa di familiare, ordinato, simmetrico e che comprendiamo. Quando questo processo cognitivo entra in gioco, le nostre menti saltano dal comprendere tutti gli elementi come componenti individuali e non correlati al vedere l'intera forma nel suo insieme, e di conseguenza, percepiamo forme e oggetti che nessuno ha creato.

Le Gestalt Law sono delle leggi basate sul concetto di figura (focus) e sfondo della figura (background) e sono divise in 7 categorie:

- **Proximity**: il principio di prossimità afferma che le cose che sono vicine tra loro sembrano essere più correlate delle cose che sono distanziate tra loro.

-  **Similarity**: la percezione tende a vedere stimoli che si assomigliano fisicamente come parte di uno stesso oggetto e stimoli che sono diversi come parte di oggetti diversi. Ad esempio, GitHub utilizza il principio di somiglianza in due modi nella seguente pagina. In primo luogo, lo consentire per distinguere diverse sezioni. Puoi immediatamente dire che la sezione grigia in alto ha uno scopo diverso rispetto alla sezione nera, anch'essa separata e diversa dalla sezione blu.

- **Closure**: Il principio di chiusura afferma che quando osserviamo una complessa
a disposizione di elementi visivi, tendiamo a cercare un modello unico e riconoscibile. In altre parole, quando vedi un'immagine che ha parti mancanti, il tuo cervello riempirà gli spazi vuoti e creerà un'immagine completa in modo da poter ancora riconoscere lo schema.

- **Continuity**: quando c’è un’intersezione tra due o più oggetti si percepisce un oggetto come singolo e interrotto. Nell'immagine sotto, ad esempio, i punti rossi nella linea curva sembrano essere più correlati ai punti neri sulla linea curva che ai punti rossi sulla linea retta orizzontale. Questo perché il tuo occhio segue naturalmente una linea o una curva, rendendo la continuazione un segnale di relazione più forte rispetto alla somiglianza del colore.

- **Common fate**: afferma che gli elementi che si muovono insieme tendono ad essere percepiti come un gruppo unificato. Pensa a guardare uno stormo di oche che si muove attraverso un cielo autunnale. Le oche volano tutte nella stessa direzione approssimativamente alla stessa velocità. Pertanto, li vediamo come un gruppo gestalt, o in questo caso, un gregge.

- **Good form**: Il principio della figura-sfondo afferma che le persone percepiscono
istintivamente gli oggetti come in primo piano o sullo sfondo. O spiccano in modo
prominente nella parte anteriore (la figura) o si allontanano nella parte posteriore (il terreno). Nell'immagine sotto, ad esempio, il tuo occhio vede immediatamente una mela bianca su uno sfondo nero.

- **Experience**: la mente tende a riconoscere modelli significativi/familiari e quindi a riempire qualsiasi informazione mancante. Nell’immagine sotto il nostro cervello riesce a farci riconoscere un cane (a sinistra) ed il papa Giovanni Paolo II (a destra).
Quando queste leggi sono in conflitto tra loro si hanno immagini impossibili o ambigue.
Una volta che abbiamo deciso quali informazioni devono essere presentate in base al contesto
dell'interazione, dobbiamo decidere come queste informazioni possono essere presentate.

La modalità visiva di per sé può supportare diverse modalità
- **statico**: testo, tabelle, immagini
- **dinamico**: gesto

Il primo modello concettuale per la presentazione multimodale di informazioni e per la progettazione di sistemi di output multimodale è WWHT (What-Which- How-Then):
- **What**: Quali sono le informazioni da presentare?
- **Which**: Quali modalità dovremmo utilizzare per presentare queste informazioni?
- **How**: Come presentare le informazioni utilizzando le modalità scelte?
- **Then**: Quindi, come gestire l'evoluzione della presentazione?
Un sistema multimodale di output mira a presentare le informazioni in modo "intelligente" sfruttando diverse modalità di comunicazione.

Questo processo di presentazione intelligente delle informazioni si basa su quattro elementi:
- **information to present**: queste informazioni sono generalmente create dal core funzionale, inoltrate dal controller di dialogo e presentate dal modulo di uscita. Ad esempio, il modulo di uscita di un telefono cellulare può presentare le seguenti informazioni semantiche: “chiamata di X”, “messaggio di X”, “livello batteria basso”, ecc.
- **interaction components**: un modo può essere associato a un insieme di modalità ed ogni singola modalità può essere associata ad un insieme di mezzi. Ad esempio: il mezzo “vibratore” permette l'espressione della modalità “vibrazione” che si percepisce attraverso la modalità “tattile”. Si possono distinguere due tipi di relazioni tra le componenti dell'interazione: “primaria” e “secondaria”. Una relazione primaria si riferisce ad un effetto desiderato mentre una relazione secondaria è un effetto collaterale. Esempio: la vibrazione del cellulare viene utilizzata per essere percepita dall'utente in modo tattile. Ciò implica una relazione primaria tra modalità “tattile” e modalità “vibrazione”. Il suono generato dalle vibrazioni è un esempio di effetto collaterale. Si può quindi aggiungere una relazione secondaria tra modalità “uditiva” e modalità “vibrazione”.

- **interaction context**: il contesto è qualsiasi informazione che può essere utilizzata per caratterizzare la situazione di un'entità. Un'entità è una persona o un oggetto considerato rilevante per l'interazione tra un utente e un'applicazione, inclusi l'utente e l'applicazione stessi.

-  **behaviour**: il modello comportamentale è probabilmente la parte più critica quando si progetta una presentazione multimodale. Identifica le migliori componenti di interazione (modo, modalità e mezzo) adattate allo stato attuale del contesto di interazione.

Un processo di analisi deve essere applicato per ottenere gli elementi richiesti. 

All'inizio è necessario raccogliere un corpus di dati. Questo corpus deve essere composto da scenari/storyboard (riferiti a situazioni nominali o degradate) ma anche da conoscenze rilevanti su campo applicativo, sistema, ambiente, ecc. La raccolta di questo corpus deve essere rigorosamente fatta e dovrebbe produrre set di dati conseguenti e diversificati. Il corpus fornisce gli elementi elementari necessari per costruire il core del sistema di output (modello comportamentale). La qualità degli output del sistema dipenderà fortemente dalla diversità del corpus.
<!--ID: 1717958283481-->
END

---

START
Basic
Fusion Techniques (a livello di acquisizione, a livello di riconoscimento, a livello di decisione, ibrida multilivello)  
Back:
Le tecniche di fusione si riferiscono ai metodi utilizzati per integrare e combinare informazioni provenienti da diverse fonti o modalità sensoriali in un sistema interattivo. Queste tecniche possono operare a diversi livelli del processo di interazione:

- **Acquisizione**: A questo livello, le informazioni provenienti da diverse fonti vengono raccolte e integrate all'interno del sistema.
- **Riconoscimento**: Qui, le informazioni integrate vengono elaborate per identificare pattern o significati utili per l'interazione.
- **Decisione**: A questo livello, le informazioni riconosciute vengono utilizzate per prendere decisioni o azioni appropriate all'interno del sistema.
- **Ibrida multilivello**: Questa è una combinazione di tecniche di fusione a più livelli, che possono essere utilizzate per affrontare sfide complesse nell'interazione uomo-macchina.  
	Le tecniche di fusione sono cruciali per migliorare l'efficienza, l'accuratezza e l'esperienza dell'utente nei sistemi interattivi che utilizzano dati o input provenienti da diverse fonti.  

ESPANSIONE


Nei sistemi multimodali, le tecniche di fusione sono per lo più applicate nelle modalità di “complementarity” e “redundancy” al fine di integrare le informazioni da esse fornite. Per quanto riguarda gli approcci delle fusioni, abbiamo due metodologie:
1. Data fusion level
2. Mathematical method

Il processo interpretativo prevede generalmente quattro fasi:
1. **Acquisizione:** l'input viene acquisito attraverso i canali di input del computer (come touch-pad per schizzo e grafia, microfono per il parlato) e poi elaborato dai relativi moduli di riconoscimento (ad esempio NLP per il parlato).
2. **Riconoscimento**
3. **Integrazione:** il sistema di fusione multimodale effettua l'integrazione degli input riconosciuti, rimuovendo eventuali ridondanze, unendo informazioni complementari da ciascuna modalità e sincronizzando le informazioni per produrre un input significativo e corretto. L'integrazione può avvenire in posizioni diverse:
   - Subito dopo il livello di acquisizione se i segnali sono sincronizzati e della stessa natura (ad es. entrambi speech input).
   - Subito dopo il livello di riconoscimento, dove vengono fusi i risultati di ogni riconoscitore utilizzando meccanismi di integrazione, e il manager emette l'interpretazione più probabile. Gli svantaggi principali della fusione precoce includono la necessità di una grande quantità di dati per l'addestramento e gli elevati costi di calcolo.
   - Fusione a livello decisione significa fondere direttamente l'informazione semantica estratta dai responsabili decisionali, adatta a modalità che differiscono sia per natura che per scala temporale.
4. **Decisione**

Ciò che avviene tra il messaggio di input espresso dall'utente e il corrispondente output restituito dal sistema è definito interpretazione di input.
<!--ID: 1717958283482-->
END

---

START
Basic
Problem of implicit interaction
Back: 
Kinetic user interfaces:
Al di là dei gesti c’è interazione implicita dove il sistema di calcolo è consapevole dei movimenti dell’utente.

Il problema dell'interazione implicita si riferisce alle sfide associate alla comprensione e alla gestione delle interazioni che avvengono senza un'esplicita azione o input da parte dell'utente. Questo può includere situazioni in cui il sistema interpreta erroneamente il comportamento dell'utente o fornisce risposte indesiderate senza un chiaro segnale da parte dell'utente.

Affrontare il problema dell'interazione implicita richiede la progettazione di sistemi intelligenti che siano in grado di comprendere il contesto e le intenzioni dell'utente in modo più accurato e reattivo, riducendo così il rischio di errori o malintesi.  
<!--ID: 1717958283483-->
END

---

START
Basic
Applicazioni pervasive 
Back: 
La tecnologia pervasiva è una tendenza emergente associata all'**incorporazione di microprocessori in oggetti di uso quotidiano**, consentendo loro di comunicare informazioni.
Le applicazioni pervasive mancano di display visivi di grandi dimensioni e dispositivi di interazione familiari, come mouse e tastiere Incorporando i sistemi negli ambienti di tutti i giorni (i cosiddetti "ambienti intelligenti") il focus delle applicazioni vocali si sposta da sistemi conversazionali a turni, di iniziativa dell'utente, a una direzione più proattiva e distribuita.
Un esempio di applicazione pervasiva è la Doorman:
<!--ID: 1717958283485-->
END

---


START
Basic
Speech Recognition (BASE MODEL e ERROR HANDLING / GROUNDING)  
Back: 
Il riconoscimento vocale, o speech recognition, è un processo attraverso il quale un computer o un dispositivo tecnologico interpreta e converte il parlato umano in testo scritto. Il modello base di riconoscimento vocale coinvolge diverse fasi, tra cui l'acquisizione del segnale audio, l'analisi e l'estrazione delle caratteristiche vocali, il confronto con modelli linguistici e l'output del testo trascritto.

Per quanto riguarda l'error handling e il grounding, questi sono aspetti critici del riconoscimento vocale che riguardano la gestione degli errori di riconoscimento e la creazione di un terreno comune di comprensione tra il sistema e l'utente. L'error handling si occupa di identificare e correggere eventuali errori di riconoscimento vocale, mentre il grounding si concentra sulla comprensione del contesto e delle intenzioni dell'utente per garantire una comunicazione efficace.

Questi processi sono cruciali per migliorare l'accuratezza e l'affidabilità del riconoscimento vocale, consentendo una migliore interazione tra l'utente e il sistema.


---


START
Basic
Cos'è il riconoscimento vocale automatico (ASR) e quali sono i termini chiave e le condizioni per valutare le prestazioni di un sistema ASR?
Back:
Il riconoscimento vocale automatico (ASR) è il processo di conversione di un segnale vocale in una sequenza di parole, utilizzando un algoritmo implementato come programma per computer.

**Terminologia:**
- **Utterance (espressione):** Qualsiasi flusso di discorso tra due periodi di silenzio. Può essere una singola parola o una frase.
- **Pronunciations:** Rappresentano come il motore di riconoscimento vocale pensa che dovrebbe suonare una parola. Le parole possono avere più pronunce.
- **Grammars:** Specificano le parole e le frasi che gli utenti possono dire in un'applicazione. Definiscono il dominio in cui funziona il motore di riconoscimento.
- **Accuracy:** Una misura quantitativa delle prestazioni di un sistema di riconoscimento vocale.

**Condizioni per valutare le prestazioni:**
- **Speaker dependence vs. independence:**
  - **Speaker Dependent:** Utilizza il training di un singolo oratore per ottimizzare il riconoscimento.
  - **Speaker Independent:** Non utilizza il training ed è destinato all'uso di più oratori.
- **Isolated, discontinuous, or continuous speech:**
  - **Isolated speech:** Singole parole.
  - **Discontinuous speech:** Frasi complete con parole separate artificialmente dal silenzio.
  - **Continuous speech:** Frasi pronunciate in modo naturale.
- **Read vs. spontaneous speech:**
  - **Read speech:** Discorso letto da script preparati.
  - **Spontaneous speech:** Discorso pronunciato spontaneamente, più difficile da riconoscere a causa di disfluenze e vocabolario illimitato.
- **Adverse conditions:** Rumore ambientale, distorsioni acustiche, microfoni diversi, banda di frequenza limitata, modo di parlare alterato.
<!--ID: 1717958283487-->
END

---

START
Basic
Gesture Style (Deictic, Manipulation, Semaphoric, Sign Language, Gesture-speech)  
Back:
Answer  
Lo stile dei gesti si riferisce alle diverse modalità attraverso cui gli utenti possono interagire con un sistema utilizzando gesti fisici o movimenti del corpo. Questi stili possono includere:

- **Deittico/Informativo/Manipolativo**: Questi gesti puntano a oggetti o posizioni specifiche nello spazio circostante, come indicare o puntare con il dito verso un oggetto (put that there, 1980)
- **Manipolazione**: Questi gesti coinvolgono l'uso di movimenti fisici per manipolare oggetti o elementi nell'ambiente, come trascinare, ruotare o ridimensionare un'immagine su uno schermo touch.
- **Semafòrico**: Questi gesti utilizzano segnali o simboli convenzionali per comunicare informazioni, come il segno di "OK" o "Stop".
- **Linguaggio dei segni**: Questo stile coinvolge l'uso di gesti specifici e simboli manuali per comunicare concetti complessi, ed è utilizzato principalmente da persone non udenti.
- **Gesto-parlato**: Questo stile combina gesti fisici con il parlato per migliorare la comunicazione e l'espressione, come l'uso delle mani durante una presentazione o una spiegazione.  
Ogni stile di gesto ha le proprie caratteristiche e applicazioni uniche, e la scelta del miglior stile dipende spesso dal contesto e dalle preferenze dell'utente. (es. il gesto ok, o il gesto della vittoria, cambia l'interpretazione a seconda del paese)
- **Non-perceptual Input"**: oggetti fisici che sono utilizzati per fare l'input. (es. il mouse o i touch screen).
- **Wearable**: un insieme di sensori che tracciano qualcosa (es. accelerometro, giroscopio…), o guanti speciali
<!--ID: 1717958283488-->
END

---

START
Basic
Che tipo di interfaccia è il touch screen? Quali tipi di touch screen esistono?   
Back:
Answer  
- resistivo: Il touch resistivo è utilizzato nei ristoranti, nelle fabbriche e negli ospedali grazie alla sua elevata resistenza ai liquidi e ai contaminanti
- capacitivo: Poiché anche il corpo umano è un conduttore elettrico, il contatto con la superficie dello schermo provoca una distorsione del campo elettrostatico dello schermo, misurabile come una variazione della capacità.
- infrarosso: raggi infrarossi che vengono interrotti dalle dita dell’utente
<!--ID: 1717958283489-->
END

---

START
Basic
Quali sono i problemi nel campo del riconoscimento audio? 
Back:
Answer  
- ambientali: segnali, rumori…
- transducer: microfono, telefono
- canali: distorsione, eco
- parlanti: sesso, età, stato psicofisico
- stili di parlata: tono della voce, produzione (silenzi), velocità
- vocabolario: termini o inflessioni dialettali
<!--ID: 1717958283491-->
END

---
START
Basic
Voice Recognition: basic model 
Back:
Answer  
A specified word sequence, $\( W \)$, produces an acoustic observation sequence $\( Y \)$, with probability $\( P(W,Y) \)$. The goal is to decode the word string, based on the acoustic observation sequence, so that the decoded string has the maximum a posteriori (MAP) probability. Given the observation sequence $\( A \)$, this is equivalent to finding

$$\[ W = \arg\max_W P(W \mid A) \]$$

Using Bayes' rule, we can also write

$$\[ P(W \mid A) = \frac{P(A \mid W) P(W)}{P(A)} \]$$

Since $\( P(A) \)$ is independent of $\( W \)$, we must find that $\( W \)$ such that

$$\[ W = \arg\max_W P(A \mid W) P(W) \]$$

$\( P(A \mid W) \)$, is generally called the acoustic model, as it estimates the probability of a sequence of acoustic observations, conditioned on the word string.

$\( P(W) \)$, is called the language model. It describes the probability associated with a postulated sequence of words.
<!--ID: 1717958283492-->
END

---

START
Basic
Che differenze ci sono tra CLI, GUI, NUI, OUI?   
Back:
Answer  
CLI: Command Line Interface, es. il terminale
GUI: Graphical User Interface, es. un programma
NUI: Natural User Interface, cioè dove l’utente fa parte dell’interfaccia. Es. kinect
OUI: Organic User Interface, "a user interface with a non-flat display" Es. Paperphone
<!--ID: 1717958283493-->
END

---

START
Basic
Descrivi e dai un esempio delle principali forme multimodali
Back:
Answer  
- Visivo, onde sonore solo in un certo spettro (400 fino ai 700 nm)
- Suono, 20Hz-20.000Hz
- Tattile, a seconda degli Hz di una certa condizione
- Olfatto, il limite lo hanno principalmente le macchine, poiché utilizziamo un naso elettronico. Il nostro naso funziona odore -> camera nasale -> cervello -> neuroni -> percezione. Quello invece elettronico odore -> sensori -> computer che fa feature extraction
<!--ID: 1717958283495-->
END

---

START
Basic
Che differenza fa tra modello e design?   
Back:
Answer  
Modello è chiedersi domande, Design è provare delle risposte. 

Per l’interazione multimodale:
- Ogni canale ha i propri limiti.
- I possibili stati del sistema sono una combinazione degli stati di ciascun canale  Quanti di essi sono veramente significativi?
- Le azioni possono provenire da canali diversi, e le risposte non sono dovute attraverso gli stessi canali
- Le possibili evoluzioni sono più difficili da anticipare e da affrontare.
<!--ID: 1717958283496-->
END

---

START
Basic
Che differenza fa tra goals e tasks?   
Back:
Answer  
I goals sono intenzioni, cosa uno vorrebbe fare.

I task sono azioni, come ottenere quello che uno vorrebbe fare.

GOMS: internal goals 
HTA: azioni esterne, tasks sono astrazioni
<!--ID: 1717958283497-->
END

---

